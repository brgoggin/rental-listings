{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ual/rental-listings\n",
    "\n",
    "This notebook analyzes the rental listings data set, computes several descriptive statistics, and visualizes market characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import necessary modules and display matplotlib plots inline within the ipython notebook webpage\n",
    "import pandas as pd, numpy as np, statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt, matplotlib.cm as cm, matplotlib.font_manager as fm\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_colors(cmap, n, start=0., stop=1., alpha=1., reverse=False):\n",
    "    '''return n-length list of rgba colors from the passed colormap name and alpha,\n",
    "       limit extent by start/stop values and reverse list order if flag is true'''\n",
    "    colors = [cm.get_cmap(cmap)(x) for x in np.linspace(start, stop, n)]\n",
    "    colors = [(r, g, b, alpha) for r, g, b, _ in colors]\n",
    "    return list(reversed(colors)) if reverse else colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the font styles\n",
    "family = 'Arial'\n",
    "title_font = fm.FontProperties(family=family, style='normal', size=18, weight='normal', stretch='normal')\n",
    "label_font = fm.FontProperties(family=family, style='normal', size=16, weight='normal', stretch='normal')\n",
    "ticks_font = fm.FontProperties(family=family, style='normal', size=14, weight='normal', stretch='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to save images consistently\n",
    "save_dpi = [96, 300]\n",
    "def save_fig(fig, title, tight=True):    \n",
    "    if tight:\n",
    "        fig.tight_layout()\n",
    "    for dpi in save_dpi:\n",
    "        save_folder = 'images/dpi_{}/'.format(dpi)\n",
    "        fig.savefig(save_folder + title, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the 2014 census data set of MSAs\n",
    "census = pd.read_csv('processed-data/census_pop_income.csv')\n",
    "census['2014_median_income'] = census['2014_median_income'].str.replace(',','').astype(int)\n",
    "census['2014_pop_est'] = census['2014_pop_est'].str.replace(',','').astype(int)\n",
    "census = census.drop(labels='notes', axis=1, inplace=False)\n",
    "census = census.set_index('region')\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are regions that either are 1) one of the 50 most populous MSAs or 2) among the top 50 in total listings posted. We used the San Jose-San Francisco-Oakland, CA CSA to accurately represent the region covered by the San Francisco Bay Area and we combined the separate regions for Los Angeles and Orange County into one to accurately represent the area covered by the census bureauâ€™s Los Angeles-Long Beach-Anaheim, CA MSA. Lastly, inlandempire corresponds to Riverside-San Bernardino MSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these are the 15 most populous metros by population, defined by census bureau 2014 estimates\n",
    "most_populous_regions = census['2014_pop_est'].sort_values(ascending=False, inplace=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions_full_names = {'newyork':'New York',\n",
    "                      'northdakota':'North Dakota',\n",
    "                      'sfbay':'SF Bay Area',\n",
    "                      'boston':'Boston',\n",
    "                      'santabarbara':'Santa Barbara',\n",
    "                      'honolulu':'Honolulu',\n",
    "                      'newjersey':'New Jersey',\n",
    "                      'losangeles':'Los Angeles',\n",
    "                      'orangecounty':'Orange County',\n",
    "                      'washingtondc':'Washington DC',\n",
    "                      'ventura':'Ventura',\n",
    "                      'longisland':'Long Island',\n",
    "                      'floridakeys':'Florida Keys',\n",
    "                      'sandiego':'San Diego',\n",
    "                      'juneau':'Juneau',\n",
    "                      'philadelphia':'Philadelphia',\n",
    "                      'chicago':'Chicago',\n",
    "                      'seattle':'Seattle',\n",
    "                      'miami':'Miami',\n",
    "                      'inlandempire':'Inland Empire',\n",
    "                      'dallas':'Dallas',\n",
    "                      'houston':'Houston',\n",
    "                      'phoenix':'Phoenix',\n",
    "                      'detroit':'Detroit',\n",
    "                      'atlanta':'Atlanta'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the full combined data set of rental listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to convert string to float and handle empty string as NaN\n",
    "def to_float(string_value):\n",
    "    string_value = string_value.strip()\n",
    "    return np.float(string_value) if string_value else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_bad_row = pd.read_csv('processed-data/usa.csv')\n",
    "remove_bad_row = remove_bad_row.drop(labels=4153401)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_bad_row.to_csv('processed-data/usa-fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the full, combined data set, converting numeric columns to float using our function\n",
    "converters = {'neighborhood':str, \n",
    "              'title':str, \n",
    "              'price':to_float, \n",
    "              'bedrooms':to_float, \n",
    "              'pid':str, \n",
    "              'date':str, \n",
    "              'link':str, \n",
    "              'sqft':to_float, \n",
    "              'sourcepage':str, \n",
    "              'longitude':to_float, \n",
    "              'latitude':to_float}\n",
    "\n",
    "all_listings = pd.read_csv('processed-data/usa-fixed.csv', converters=converters)\n",
    "\n",
    "# if not using the fixed csv file, you must drop this row that has a url in its date column and messes up the processing\n",
    "#all_listings = all_listings.drop(labels=4153401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_listings = all_listings.rename(columns={'price':'rent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of rows in the full data set (includes dupes/re-posts)\n",
    "all_listings['pid'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are nearly 11 million listings in the full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate rent/sqft\n",
    "all_listings['rent_sqft'] = all_listings['rent'] / all_listings['sqft']\n",
    "all_listings[['rent','sqft','rent_sqft']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, parse dates from the date column and visualize the full (may contain re-posts) data set by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the date column to yyyy-mm-dd date format\n",
    "all_listings['date'] = pd.to_datetime(all_listings['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create ticks and tick labels for the time series\n",
    "listings_per_date = all_listings['date'].value_counts()\n",
    "listings_per_date = listings_per_date.sort_index()\n",
    "listings_per_date = listings_per_date.reset_index()\n",
    "xticks = listings_per_date.iloc[range(0, len(listings_per_date), 7)].index\n",
    "xtick_labels = listings_per_date.loc[xticks, 'index']\n",
    "xtick_labels = [str(x).split()[0] for x in xtick_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the total number of listings (includes dupes/re-posts) posted on each day in the data set\n",
    "ax = listings_per_date.plot(kind='line', figsize=[10, 6], ylim=[0,300000], linewidth=3, \n",
    "                            marker='o', markeredgewidth=0, alpha=0.7, color='#003399')\n",
    "ax.grid(True)\n",
    "ax.set_title('Total rental listings posted per day', fontproperties=title_font)\n",
    "ax.set_ylabel('Number of listings posted', fontproperties=label_font)\n",
    "ax.legend_.remove()\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xtick_labels, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(ticks_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'date_count_listings_posted.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set covers mid May through mid July, 2014. The x-axis labels represent Sundays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate day of the week each listing was posted\n",
    "all_listings['day_of_week'] = all_listings['date'].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Next, de-duplicate the data set based on the 'pid' column and examine the unique vs duplicate listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first extract the subdomain/region from the link column\n",
    "all_listings['region'] = all_listings['link'].str.extract('http://(.*).craigslist.org', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# de-dupe data set and create a new dataframe to hold the unique listings\n",
    "unique_listings = pd.DataFrame(all_listings.drop_duplicates(subset='pid', inplace=False))\n",
    "len(unique_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a view of the duplicate listings\n",
    "duplicate_listings = all_listings[~all_listings.index.isin(unique_listings.index)]\n",
    "len(duplicate_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the top 5 PIDs with the most duplicates\n",
    "most_dupe_pids = duplicate_listings['pid'].value_counts()\n",
    "most_dupe_pids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the listings for the PID with the most duplicates - it is in brooklyn\n",
    "cols = ['region', 'pid', 'neighborhood', 'rent', 'bedrooms', 'date']\n",
    "all_listings[all_listings['pid']==most_dupe_pids.index[0]][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the listing's creator is re-publishing it every couple of days. This seems to maintain the same pid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the ratios of unique to duplicate listings for each region\n",
    "listings_ratios = pd.DataFrame()\n",
    "\n",
    "# number of total listings for each region\n",
    "listings_ratios['all_listings'] = all_listings['region'].value_counts()\n",
    "\n",
    "# number of duplicate listings for each region (ie, listings that share a pid with at least one other listing)\n",
    "listings_ratios['duplicate_listings'] = duplicate_listings['region'].value_counts()\n",
    "\n",
    "# number of unique listings for the region (ie, none share a pid with another listing)\n",
    "listings_ratios['unique_listings'] = unique_listings['region'].value_counts()\n",
    "\n",
    "# percent of this region's listings that are duplicates\n",
    "listings_ratios['duplicate_ratio'] = listings_ratios['duplicate_listings'] / listings_ratios['all_listings']\n",
    "\n",
    "# percent of this region's listings that are unique (ie, not duplicates)\n",
    "listings_ratios['unique_ratio'] = listings_ratios['unique_listings'] / listings_ratios['all_listings']\n",
    "\n",
    "listings_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the ratios of unique and duplicate listings, by region\n",
    "countdata = listings_ratios.sort_values(by='all_listings', ascending=False)[['unique_listings', 'duplicate_listings']].head(20)\n",
    "countdata.columns = ['Unique Listings', 'Duplicate Listings']\n",
    "ax = countdata.plot(kind='bar',\n",
    "                    stacked=True,\n",
    "                    figsize=[9, 6], \n",
    "                    width=0.6, \n",
    "                    alpha=0.5, \n",
    "                    color=['b','m'],\n",
    "                    edgecolor='k',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(countdata.index, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Unique and duplicate rental listings, by region', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Total number of listings', fontproperties=label_font)        \n",
    "\n",
    "save_fig(plt.gcf(), 'count_unique_duplicate_listings.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# which regions have the largest ratio of duplicate listings\n",
    "listings_ratios = listings_ratios.sort_values(by='unique_ratio')\n",
    "listings_ratios.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, filter the data set by retaining only those rows that contain rent and sqft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thorough listings are unique listings with rent and sqft data\n",
    "thorough_listings = pd.DataFrame(unique_listings)\n",
    "thorough_listings = thorough_listings[thorough_listings['rent'] > 0]\n",
    "thorough_listings = thorough_listings[thorough_listings['sqft'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for comparison, what are the counts of the differents sets?\n",
    "print('Count of all listings:', len(all_listings))\n",
    "print('Count of unique listings:', len(unique_listings))\n",
    "print('Count of thorough listings:', len(thorough_listings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All listings are everything we collected. \n",
    "\n",
    "Unique listings are those with a unique pid (ie, re-posts are not counted). \n",
    "\n",
    "Thorough listings are unique listings with rent and sq foot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what is the median rent per sqft across the set of thorough listings\n",
    "thorough_listings['rent_sqft'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for comparison, the median rent/sqft for the entire, original data set is very similar\n",
    "all_listings['rent_sqft'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# describe the rent-per-sqft vector\n",
    "thorough_listings['rent_sqft'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the mean is pulled up by ridiculous high outliers (like $214 million per sq ft). There are also some ridiculous low outliers. So, let's filter out outliers that fall outside of a reasonable range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data set, retaining listings that have reasonable values for rent, sqft, and rent/sqft\n",
    "Define reasonable by the 0.2 and 99.8 percentiles for rent, sqft, and rent/sqft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in this cell, define the values by which we will filter the 3 columns\n",
    "upper_percentile = 0.998\n",
    "lower_percentile = 0.002\n",
    "\n",
    "# how many rows would be within the upper and lower percentiles?\n",
    "upper = int(len(thorough_listings) * upper_percentile)\n",
    "lower = int(len(thorough_listings) * lower_percentile)\n",
    "\n",
    "# get the rent/sqft values at the upper and lower percentiles\n",
    "rent_sqft_sorted = thorough_listings['rent_sqft'].sort_values(ascending=True, inplace=False)\n",
    "upper_rent_sqft = rent_sqft_sorted.iloc[upper]\n",
    "lower_rent_sqft = rent_sqft_sorted.iloc[lower]\n",
    "\n",
    "# get the rent values at the upper and lower percentiles\n",
    "rent_sorted = thorough_listings['rent'].sort_values(ascending=True, inplace=False)\n",
    "upper_rent = rent_sorted.iloc[upper]\n",
    "lower_rent = rent_sorted.iloc[lower]\n",
    "\n",
    "# get the sqft values at the upper and lower percentiles\n",
    "sqft_sorted = thorough_listings['sqft'].sort_values(ascending=True, inplace=False)\n",
    "upper_sqft = sqft_sorted.iloc[upper]\n",
    "lower_sqft = sqft_sorted.iloc[lower]\n",
    "\n",
    "print('valid rent_sqft range:', [lower_rent_sqft, upper_rent_sqft])\n",
    "print('valid rent range:', [lower_rent, upper_rent])\n",
    "print('valid sqft range:', [lower_sqft, upper_sqft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a boolean vector mask to filter out any rows with rent_sqft outside of the reasonable values\n",
    "rent_sqft_mask = (thorough_listings['rent_sqft'] > lower_rent_sqft) & (thorough_listings['rent_sqft'] < upper_rent_sqft)\n",
    "\n",
    "# create boolean vector masks to filter out any rows with rent or sqft outside of the reasonable values\n",
    "rent_mask = (thorough_listings['rent'] > lower_rent) & (thorough_listings['rent'] < upper_rent)\n",
    "sqft_mask = (thorough_listings['sqft'] > lower_sqft) & (thorough_listings['sqft'] < upper_sqft)\n",
    "\n",
    "# filter the thorough listings according to these masks\n",
    "filtered_listings = pd.DataFrame(thorough_listings[rent_sqft_mask & rent_mask & sqft_mask])\n",
    "len(filtered_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many 'unreasonable' listings did we filter out?\n",
    "count_removed = len(thorough_listings) - len(filtered_listings)\n",
    "print(count_removed)\n",
    "print(count_removed / float(len(thorough_listings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save two regional subsets for tract-level analysis\n",
    "filtered_listings[filtered_listings['region']=='sfbay'].to_csv('sfbay-filtered-listings.csv', index=False, encoding='utf-8')\n",
    "filtered_listings[filtered_listings['region']=='seattle'].to_csv('seattle-filtered-listings.csv', index=False, encoding='utf-8')\n",
    "filtered_listings[filtered_listings['region']=='newyork'].to_csv('newyork-filtered-listings.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we filtered out 23,601 or 0.79% of the thorough listings. Although we discarded values below the 0.2% and the 99.8%, we did it on three separate variables (rent, sqft, rent/sqft) so the total number of rows discarded was higher than 0.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the number of filtered rental listings by region\n",
    "countdata = filtered_listings['region'].value_counts().head(30)\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[10, 6], \n",
    "                    width=0.6, \n",
    "                    alpha=0.5, \n",
    "                    color='g',\n",
    "                    edgecolor='k',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(countdata.index, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('The most rental listings (filtered), by region', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Number of listings per region', fontproperties=label_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'count_most_listings_filtered.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a couple of measures of statistical dispersion to see how the thorough listings differ from this filtered set of reasonable listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the interquartile range of the thorough listings\n",
    "print(thorough_listings['rent_sqft'].describe()['75%'] - thorough_listings['rent_sqft'].describe()['25%'])\n",
    "\n",
    "# calculate the interquartile range of the filtered listings\n",
    "print(filtered_listings['rent_sqft'].describe()['75%'] - filtered_listings['rent_sqft'].describe()['25%'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interquartile ranges are very similar for each -- filtering didn't change this measure of statistical dispersion much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the std deviation of the thorough listings\n",
    "print(thorough_listings['rent_sqft'].std())\n",
    "\n",
    "# calculate the std deviation of the filtered listings\n",
    "print(filtered_listings['rent_sqft'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation dropped drastically from 125,085.11 to 0.86 after filtering out just 0.79% of the thorough listings that were the greatest outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at how descriptive stats changed after filtering by reasonable values\n",
    "cols = ['rent','sqft','rent_sqft']\n",
    "c = thorough_listings[cols].describe().rename(columns={'rent':'rent1','sqft':'sqft1','rent_sqft':'rent_sqft1'})\n",
    "f = filtered_listings[cols].describe().rename(columns={'rent':'rent2','sqft':'sqft2','rent_sqft':'rent_sqft2'})\n",
    "cf = pd.concat(objs=[c,f], axis=1)\n",
    "cf = cf.reindex(columns=['rent1','rent2','sqft1','sqft2','rent_sqft1','rent_sqft2'])\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see how the descriptive stats changed in each field from before (the 1s) to after (the 2s) we filtered by reasonable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot histograms of rent, sqft, and rent/sqft values in the filtered data set\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=[16, 5])\n",
    "bins = 50\n",
    "color = 'k'\n",
    "edgecolor = 'None'\n",
    "alpha = 0.5\n",
    "ylim = [0, 660000]\n",
    "\n",
    "# histogram of rents\n",
    "ax0 = filtered_listings['rent'].hist(ax=axes[0], bins=bins, color=color, edgecolor=edgecolor, alpha=alpha)\n",
    "ax0.set_ylim(ylim)\n",
    "ax0.set_xlabel('Rent', fontproperties=label_font)\n",
    "ax0.set_ylabel('Listings Count', fontproperties=label_font)\n",
    "\n",
    "# histogram of sqft\n",
    "ax1 = filtered_listings['sqft'].hist(ax=axes[1], bins=bins, color=color, edgecolor=edgecolor, alpha=alpha)\n",
    "ax1.set_ylim(ylim)\n",
    "ax1.set_xlabel('Square footage', fontproperties=label_font)\n",
    "\n",
    "# histogram of rent/sqft\n",
    "ax2 = filtered_listings['rent_sqft'].hist(ax=axes[2], bins=bins, color=color, edgecolor=edgecolor, alpha=alpha)\n",
    "ax2.set_ylim(ylim)\n",
    "ax2.set_xlabel('Rent/square foot', fontproperties=label_font)\n",
    "\n",
    "fig.suptitle('Histograms of rent, square footage, and rent/square foot values in the filtered data set', \n",
    "             fontproperties=title_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'hist_rent_sqft_rentpersqft.png', tight=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These histograms show the distribution of these values across the filtered data set. Now plot continuous distributions of rent/sqft use KDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, sort the 15 most populous metros by median rent/sqft\n",
    "median_rent_sqft_by_region = filtered_listings.groupby('region')['rent_sqft'].median()\n",
    "median_rent_sqft_populous_regions = median_rent_sqft_by_region[most_populous_regions.index].sort_values(ascending=False, \n",
    "                                                                                                        inplace=False)\n",
    "metro_names = list(median_rent_sqft_populous_regions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get a different color for each of the lines to plot\n",
    "color_list = get_colors('spectral', len(metro_names), start=0, stop=0.9, reverse=True)\n",
    "#color_list = get_colors('plasma', len(metro_names), start=0.15, stop=0.85, reverse=False)\n",
    "#color_list = get_colors('viridis', len(metro_names), start=0, stop=0.9, reverse=False)\n",
    "\n",
    "for name, color in zip(metro_names, color_list):\n",
    "    values = filtered_listings[filtered_listings['region']==name]['rent_sqft']\n",
    "    ax = values.plot(kind='kde', color=color, linewidth=2, alpha=0.6, figsize=[10, 7])\n",
    "    \n",
    "ax.grid(False)\n",
    "ax.set_xlim([0,6])\n",
    "ax.set_ylim([0,2.25])\n",
    "ax.set_xlabel('Rent per square foot (USD)', fontproperties=label_font)\n",
    "ax.set_ylabel('Density', fontproperties=label_font)\n",
    "ax.set_title('Probability density of rent/sqft values for the 15 most populous metros', fontproperties=title_font)\n",
    "ax.legend([regions_full_names[x] for x in metro_names], prop=ticks_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'kde_most_populous_metros.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability densities can exceed 1 because the function is defined over a continuous interval. Probabilities are measured over intervals rather than at single points, so the area beneath the curve between any two points represents the probability for that interval. The integral of the function (the total area under the curve) must equal 1, similar to how the sum of all probabilities in a discrete distribution must equal 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 415 regions in the entire data set. Let's see the KDEs for all 415 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, sort all regions ascending by median rent/sqft to print high values last (ie, on top of the other lines)\n",
    "region_names = list(median_rent_sqft_by_region.sort_values(ascending=True, inplace=False).index)\n",
    "\n",
    "# get one color from red through blue (don't use violets/grays) for each line/region\n",
    "color_list = get_colors('spectral', len(region_names), start=0.13, stop=0.93)\n",
    "#color_list = get_colors('viridis', len(region_names), start=0, stop=0.9, reverse=True)\n",
    "\n",
    "for name, color in zip(region_names, color_list):\n",
    "    values = filtered_listings[filtered_listings['region']==name]['rent_sqft']\n",
    "    ax = values.plot(kind='kde', color=color, linewidth=.75, alpha=0.5, figsize=[10, 7])\n",
    "    \n",
    "ax.grid(False)\n",
    "ax.set_xlim([0, 4])\n",
    "ax.set_ylim([0, 6.3])\n",
    "ax.set_xlabel('Rent per square foot (USD)', fontproperties=label_font)\n",
    "ax.set_ylabel('Density', fontproperties=label_font)\n",
    "ax.set_title('Probability density of rent/sqft values for each region', fontproperties=title_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'kde_all_regions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the KDE of rent/sqft for every region in the filtered data set. Each region has its own line, colored by median rent/sqft for that region (high=red, low=blue/violet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the most and least expensive regions in the filtered data set, by price/sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a categorical variable by dividing the data set into quantiles\n",
    "num_bins = 5\n",
    "bin_labels = [ str(n + 1) for n in range(num_bins) ]\n",
    "quantiles = pd.qcut(x=filtered_listings['rent_sqft'], q=num_bins, labels=bin_labels)\n",
    "filtered_listings['rent_sqft_cat'] = quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab the most and least expensive regions, by median rent per sq ft\n",
    "most_expensive = median_rent_sqft_by_region.sort_values(ascending=False, inplace=False)\n",
    "least_expensive = median_rent_sqft_by_region.sort_values(ascending=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_median_rent_sqft = filtered_listings['rent_sqft'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the most expensive regions\n",
    "countdata = most_expensive.head(15)\n",
    "countdata = countdata.rename({'nd':'northdakota', 'keys':'floridakeys'})\n",
    "xlabels = [regions_full_names[x] for x in countdata.index]\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[9, 6], \n",
    "                    width=0.8, \n",
    "                    alpha=0.7, \n",
    "                    color='#003399',\n",
    "                    edgecolor='w',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(xlabels, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Most expensive regions, by median rent per square foot', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Median rent per square foot (USD)', fontproperties=label_font)\n",
    "\n",
    "# draw a line showing the median rent/sqft in the filtered data set\n",
    "plt.plot([-1, 60], [filtered_median_rent_sqft, filtered_median_rent_sqft], 'k-', color='k', alpha=1, linewidth=1)\n",
    "\n",
    "save_fig(plt.gcf(), 'median_rent_sqft_most_expensive_regions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The horizontal line depicts the median rent/sqt across the entire filtered data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the least expensive regions are very small\n",
    "least_expensive.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the rent per sq ft for the 15 most populous metros in the U.S.\n",
    "countdata = median_rent_sqft_populous_regions\n",
    "xlabels = [regions_full_names[x] for x in countdata.index]\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[9, 6], \n",
    "                    width=0.8, \n",
    "                    alpha=0.7, \n",
    "                    color='#003399',\n",
    "                    edgecolor='w',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(xlabels, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Most populous metro areas, by median rent per square foot', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Median rent per square foot (USD)', fontproperties=label_font)\n",
    "\n",
    "# draw a line showing the median rent/sqft in the filtered data set\n",
    "plt.plot([-1, 60], [filtered_median_rent_sqft, filtered_median_rent_sqft], 'k-', color='k', alpha=1, linewidth=1)\n",
    "\n",
    "save_fig(plt.gcf(), 'median_rent_sqft_populous_metros.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get summary data for regions and analyze affordability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to 2014 American Community Survey 1-Year Estimates of Median household income in the past 12 months (in 2014 inflation-adjusted dollars) (B19013) to assess the rent burden, and to Annual Estimates of the Resident Population 2014 population estimates (as of July 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the regions that appear in the census data file we loaded at the beginning\n",
    "# rename orangecounty to losangeles to combine into one to match census metro area\n",
    "fl_regions = pd.DataFrame(filtered_listings)\n",
    "fl_regions['region_census'] = fl_regions['region'].map(lambda x: x if not x=='orangecounty' else 'losangeles')\n",
    "fl_regions = fl_regions[filtered_listings['region_census'].isin(census.index)]\n",
    "\n",
    "print len(fl_regions['region_census'].value_counts())\n",
    "print len(fl_regions)\n",
    "print len(fl_regions) / float(len(filtered_listings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 58 regions in the census data file (out of 415 total in the filtered data set, or 14%), comprising a sample size of 2,297,566 rental listings, or 77.9% of the filtered data set. Also, the fl_regions dataframe combines the losangeles and orangecounty regions into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what is the nationwide median rent and sq ft?\n",
    "nationwide_median_rent = filtered_listings['rent'].median()\n",
    "print nationwide_median_rent\n",
    "\n",
    "nationwide_median_sqft = filtered_listings['sqft'].median()\n",
    "print nationwide_median_sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate some stats on affordability and region summaries\n",
    "regions = census\n",
    "regions['count_listings'] = fl_regions.groupby('region_census').size().astype(int)\n",
    "regions['median_rent'] = fl_regions.groupby('region_census')['rent'].median().astype(int)\n",
    "regions['median_sqft'] = fl_regions.groupby('region_census')['sqft'].median().astype(int)\n",
    "regions['median_rent_sqft'] = fl_regions.groupby('region_census')['rent_sqft'].median().round(2)\n",
    "regions['rent_proportion'] = (regions['median_rent'] / (regions['2014_median_income'] / 12)).round(2)\n",
    "regions['rental_power'] = (nationwide_median_rent / regions['median_rent_sqft']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to csv and display the head\n",
    "regions = regions.sort_values(by='2014_pop_est', ascending=False, inplace=False)\n",
    "regions.to_csv('processed-data/regions_census_summary.csv', index=True)\n",
    "regions.head()[['2014_median_income','2014_pop_est','count_listings','median_rent','median_sqft',\n",
    "                'median_rent_sqft','rent_proportion','rental_power']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014 median income is from the 2014 American Community Surveyâ€™s 1-year estimates of median household income (in 2014 inflation-adjusted dollars). 2014 population estimates are from the American Community Surveyâ€™s 2014 annual estimates of resident population (as of July 1). Median rent, sqft, and rent/sqft are calculated from the filtered data set (note: median rent/sqft is not equivalent to median rent/median sqft). The rent proportion is the ratio of median rent to median monthly household income. Sqft rental power is an estimate of how many square feet can be rented in each region for the nationwide median rent, and is calculated by dividing nationwide median rent by regional median rent per sqft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at some simple correlations between these variables\n",
    "xs = ['2014_pop_est', '2014_median_income', 'count_listings', '2014_median_income']\n",
    "ys = ['count_listings', 'count_listings', 'median_rent_sqft', 'median_rent_sqft']\n",
    "for x, y in zip(xs, ys):\n",
    "    print '{} vs {}'.format(y, x)\n",
    "    r, p = pearsonr(regions[x], regions[y])\n",
    "    print 'r={:0.3f}, p={:0.3f}'.format(r, p)\n",
    "    regions.plot(kind='scatter', x=x, y=y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the rent burden for the 15 most populous metros in the U.S.\n",
    "countdata = regions['rent_proportion'][most_populous_regions.index].sort_values(ascending=False, inplace=False)\n",
    "xlabels = [regions_full_names[x] for x in countdata.index]\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[9, 6], \n",
    "                    width=0.8, \n",
    "                    alpha=0.7, \n",
    "                    color='#003399',\n",
    "                    edgecolor='w',\n",
    "                    ylim=[0, 0.47],\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(xlabels, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Most populous metro areas, by proportion of income spent on rent', fontproperties=title_font)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Ratio of median rent to median household income', fontproperties=label_font)\n",
    "\n",
    "# draw a line showing the rent burden\n",
    "plt.plot([-1, 60], [0.3, 0.3], 'k-', color='k', alpha=1, linewidth=1)\n",
    "\n",
    "save_fig(plt.gcf(), 'rent_proportion.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.3 is the common threshold for rent burden. Here we can see 5 of the 15 most populous regions' median rents exceed 30% of the metro areas' median monthly household income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on each region's median rent/sqft, how many square feet can you rent in each of the 15 most populous metro areas for the nationwide median rent of $1,145?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the sqft you can buy for the nationwide median rent for the 15 most populous metros in the U.S.\n",
    "countdata = countdata = regions['rental_power'][most_populous_regions.index].sort_values(ascending=False, inplace=False)\n",
    "xlabels = [regions_full_names[x] for x in countdata.index]\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[9, 6], \n",
    "                    width=0.8, \n",
    "                    alpha=0.7, \n",
    "                    color='#003399',\n",
    "                    edgecolor='w',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(xlabels, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Sq ft one can rent in most populous metros, for nationwide median rent', y=1.02, fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Square feet', fontproperties=label_font)\n",
    "\n",
    "# draw a line showing the nationwide median sqft\n",
    "plt.plot([-1, 16], [nationwide_median_sqft, nationwide_median_sqft], 'k-', color='k', alpha=1, linewidth=1)\n",
    "\n",
    "save_fig(plt.gcf(), 'rental_power.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The horizontal line depicts the nationwide median square footage in the filtered data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare rental listings by regions and # bedrooms to HUD fair market rents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the ratio of listings below the fair market rent, as defined by HUD. FMRs generally correspond to 40th percentile rents and FMR areas generally correspond to metropolitan areas, but inconsistently so as HUD uses a more complicated formula to determine percentiles and area boundaries in different circumstances. Dallas is excluded here as the Dallas metro FMR area uses only disaggregate \"Small Area FMRs\" as defined by ZIP codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the HUD 2014 median rents and fair market rents data (per region and per # of bedrooms)\n",
    "hud = pd.read_csv('processed-data/hud_frm_median_rent_metro_bedrooms.csv', index_col='region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all the filtered listings for our regions, that have 1-4 bedrooms\n",
    "reg_rent = filtered_listings[filtered_listings['region'].isin(hud.index)][['region', 'bedrooms', 'rent']]\n",
    "reg_rent.index = [reg_rent['region'], reg_rent['bedrooms']]\n",
    "reg_rent = reg_rent[reg_rent['bedrooms'].isin([1,2,3,4])]\n",
    "reg_rent.sort_index(inplace=True) #sort index for faster performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign the fair market rent value (determined by region and # of bedrooms) to each row in the dataframe\n",
    "reg_rent['fmr'] = None\n",
    "for name in hud.index:\n",
    "    for br in [1,2,3,4]:\n",
    "        reg_rent.loc[(name, br), 'fmr'] = hud.loc[name, 'FMR_{0}'.format(br)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what is the ratio of listings below FMR to total listings, in the entire filtered data set\n",
    "reg_rent['below_fmr'] = reg_rent['rent'] <= reg_rent['fmr']\n",
    "reg_rent_vc = reg_rent['below_fmr'].value_counts()\n",
    "fmr_ratio = reg_rent_vc[True] / float(reg_rent_vc.sum())\n",
    "fmr_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37% of the listings in the filtered data set are at/below fair market rent for that region and number of bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# break out the proportion of listings below FMR, by bedrooms (agnostic to region)\n",
    "reg_rent_below = reg_rent[reg_rent['below_fmr']]\n",
    "below_FMR_br = reg_rent_below.groupby(['region', 'bedrooms']).count()['below_fmr'].unstack().sum()\n",
    "total_br = reg_rent.groupby(['region', 'bedrooms']).count()['below_fmr'].unstack().sum()\n",
    "fmr_ratio_by_br = below_FMR_br / total_br\n",
    "fmr_ratio_by_br.index = [int(label) for label in fmr_ratio_by_br.index]\n",
    "fmr_ratio_by_br.loc['all_1-4'] = fmr_ratio\n",
    "fmr_ratio_by_br.name = 'total'\n",
    "fmr_ratio_by_br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broken out by number of bedrooms, 29% of the 1 bedroom listings are below FMR, 36% of the 2 bedrooms, 51% of the 3 bedrooms, and 45% of the 4 bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# break out the proportion of listings below FMR, by region\n",
    "reg_rent_below = reg_rent[reg_rent['below_fmr']]\n",
    "ratio_below_fmr = reg_rent_below.groupby('region').count()['below_fmr'] / reg_rent.groupby('region').count()['below_fmr']\n",
    "ratio_below_fmr.name = 'all_1-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# break out the proportion of listings below FMR, by region and bedrooms\n",
    "ratio_below_fmr_br = reg_rent_below.groupby(['region','bedrooms']).count()['below_fmr'] / reg_rent.groupby(['region','bedrooms']).count()['below_fmr']\n",
    "ratio_below_fmr_br = ratio_below_fmr_br.unstack()\n",
    "ratio_below_fmr_br.columns = [int(label) for label in ratio_below_fmr_br.columns]\n",
    "ratio_below_fmr_br = pd.concat([ratio_below_fmr_br, ratio_below_fmr], axis=1)\n",
    "ratio_below_fmr_br.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of listings at/below the FMR varies considerably by region and by number of bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add the totals to the bottom of the dataframe, round it, and save to csv\n",
    "ratio_below_fmr_br = ratio_below_fmr_br.append(fmr_ratio_by_br)\n",
    "np.round(ratio_below_fmr_br, 2).to_csv('processed-data/regions_fmr_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the proportion of listings at/below FMR for the 15 most populous metros\n",
    "countdata = ratio_below_fmr_br['all_1-4'][most_populous_regions.index].sort_values(ascending=False, inplace=False)\n",
    "countdata = countdata.drop(labels='dallas', axis=0)\n",
    "xlabels = [regions_full_names[x] for x in countdata.index]\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[9, 6], \n",
    "                    width=0.8, \n",
    "                    alpha=0.7, \n",
    "                    color='#003399',\n",
    "                    edgecolor='w',\n",
    "                    ylim=[0, 0.8],\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(xlabels, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Most populous metros, by proportion of listings below fair market rent', y=1.01, fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Proportion of listings', fontproperties=label_font)\n",
    "\n",
    "# draw a line showing the rent burden\n",
    "plt.plot([-1, 60], [0.4, 0.4], 'k-', color='k', alpha=1, linewidth=1)\n",
    "\n",
    "save_fig(plt.gcf(), 'fmr_proportions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 14 most populous metro areas (i.e. the 15, sans Dallas, for whom there is no metro-level FMR data) by proportion of listings in the filtered data set at or below the HUD fair market rent value. The horizontal line marks the 40th percentile: for reference, HUD bases their FMRs on the 40th percentile rent.\n",
    "\n",
    "While regions like Phoenix, Atlanta, and Detroit have greater than 60% of their listings below the fair market rent, New York and Boston have single digit percentages of listings below the fair market rent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the data set against HUD median rents by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get median rent per metro per # of bedrooms (1-4)\n",
    "mask = filtered_listings['region'].isin(regions.sort_index(inplace=False).index) & filtered_listings['bedrooms'].isin([1,2,3,4])\n",
    "region_br_rent = filtered_listings[mask].groupby(['region', 'bedrooms'])['rent'].median().unstack()\n",
    "region_br_rent.columns = ['clist_{0}'.format(br) for br in pd.Series(region_br_rent.columns).astype(int)]\n",
    "\n",
    "region_br_rent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the Craigslist median rents and the HUD median rents\n",
    "region_hud = pd.concat([region_br_rent, hud], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the relationship between the Craigslist median rents and the HUD median rents (by region), first scatter plot them. HUD median rents are calculated for \"fair market rent areas\" that with a few exceptions generally correspond to OMB definitions of metropolitan areas, as these generally correspond well to housing market areas. However, these are median rent values, not FMRs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 7)\n",
    "\n",
    "labels = ['1 br', '2 br', '3 br', '4 br']\n",
    "plots = []\n",
    "plots.append(ax.scatter(x=region_hud['HUD_median_1'], y=region_hud['clist_1'], c='g', edgecolor='k', alpha=.4, s=50))\n",
    "plots.append(ax.scatter(x=region_hud['HUD_median_2'], y=region_hud['clist_2'], c='b', edgecolor='k', alpha=.4, s=50))\n",
    "plots.append(ax.scatter(x=region_hud['HUD_median_3'], y=region_hud['clist_3'], c='m', edgecolor='k', alpha=.4, s=50))\n",
    "plots.append(ax.scatter(x=region_hud['HUD_median_4'], y=region_hud['clist_4'], c='orange', edgecolor='k', alpha=.4, s=50))\n",
    "\n",
    "ax.set_xlim([0,4100])\n",
    "ax.set_ylim([0,4100])\n",
    "\n",
    "ax.set_title('Craigslist median rent vs HUD median rent, by metro area', fontproperties=title_font)\n",
    "ax.set_xlabel('HUD median rent by metro area (USD)', fontproperties=label_font)\n",
    "ax.set_ylabel('Craigslist median rent by metro area (USD)', fontproperties=label_font)\n",
    "plt.legend(plots, labels, loc=4, prop=ticks_font)\n",
    "\n",
    "# draw a line indicating a perfect linear relationship\n",
    "plt.plot([0, 4100], [0, 4100], 'k-', color='k', alpha=0.2, linewidth=1.5)\n",
    "\n",
    "save_fig(plt.gcf(), 'median_rent_hud_craigslist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points are above the line when Craigslist median rent is greater than HUD median rent, below the line when HUD median rent is greater than Craigslist median rent, and on the line when the two median rents are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot same data, but with simple bivariate regression lines\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 7)\n",
    "bedrooms = [1, 2, 3, 4]\n",
    "labels = ['1 br', '2 br', '3 br', '4 br']\n",
    "color_list = get_colors('YlOrRd', n=len(labels), start=0.25, stop=0.95)\n",
    "plots = []\n",
    "\n",
    "for br, c in zip(bedrooms, color_list):\n",
    "    \n",
    "    # regress craigslist data on HUD data\n",
    "    X = region_hud['HUD_median_{}'.format(br)]\n",
    "    Y = region_hud['clist_{}'.format(br)]\n",
    "    results = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "    \n",
    "    # calculate estimated y values for regression line\n",
    "    X_line = pd.Series(X)\n",
    "    X_line.loc[0] = 0\n",
    "    X_line.loc[4100] = 4100\n",
    "    Y_est = X_line * results.params[1] + results.params[0]\n",
    "    \n",
    "    # draw points and regression line\n",
    "    plots.append(ax.scatter(X, Y, c=c, edgecolor='#333333', alpha=0.8, s=40, zorder=2))\n",
    "    ax.plot(X_line, Y_est, c=c, alpha=0.5, linewidth=2, zorder=1)\n",
    "\n",
    "ax.set_xlim([0,4100])\n",
    "ax.set_ylim([0,4100])\n",
    "\n",
    "ax.set_title('Craigslist median rent vs HUD median rent, by metro area', fontproperties=title_font)\n",
    "ax.set_xlabel('HUD median rent by metro area (USD)', fontproperties=label_font)\n",
    "ax.set_ylabel('Craigslist median rent by metro area (USD)', fontproperties=label_font)\n",
    "plt.legend(plots, labels, loc=4, prop=ticks_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'median_rent_hud_craigslist_regression.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now get the correlation coefficient and statistical significance for each number of bedrooms\n",
    "N = len(region_hud)\n",
    "for br in [1, 2, 3, 4]:\n",
    "    r, p = pearsonr(region_hud['clist_{}'.format(br)], region_hud['HUD_median_{}'.format(br)])\n",
    "    r_square = r ** 2\n",
    "    t = r * (np.sqrt((N - 2)/(1 - r_square)))\n",
    "    \n",
    "    print '{} br:'.format(br), 'r={:0.2f},'.format(r), 'r-square={:.2f},'.format(r_square),\n",
    "    print 't={:05.2f},'.format(t), 'df={},'.format(N-2), 'p={:0.23f}'.format(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations between HUD and Craigslist median rents are positive, strong, and statistically significant (p<.0001). The coefficient of determinations (r<sup>2</sup>) reveal that 83%, 81%, 77%, and 63% (for 1, 2, 3, and 4 bedroom listings, respectively) of the variation in Craigslist median rents (per region) can be explained by HUD median rents.\n",
    "\n",
    "Now perform a dependent samples t-test for each number of bedrooms to compare the Craigslist and HUD means (of median rents by region) to see if they are significantly different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dependent samples t-test to see if means are significantly different\n",
    "for br in [1, 2, 3, 4]:\n",
    "    t, p = ttest_rel(region_hud['clist_{}'.format(br)], region_hud['HUD_median_{}'.format(br)])\n",
    "    print br, 'br:', 't={},'.format(round(t, 2)), 'p={}'.format(round(p, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis H<sub>0</sub> is that the means are the same. We can reject the null for 1 br (p<.01) and 3 br (p<.02), indicating that the means of Craigslist and HUD are statistically significantly different. We cannot reject the null for 2 br (p=.07) or 4 br (p=.69), indicating that the means of Craigslist and HUD are not statistically significantly different (ie, we would expect a t-statistic of this size 7% and 69% of the time when there is no real difference between the population means).\n",
    "\n",
    "Two-sample t-tests require that a set of conditions be met. First, each sample must be simple random sampling - ours aren't exactly that. Second, the sampling distribution should be normal - ie, symmetric, unskewed, and without outliers. None of these samples are normally distributed - that's to be expected with real world data. But most of these samples are considerably positively skewed by outliers, so the t-test may not really be appropriate here.\n",
    "\n",
    "Instead, let's try to get at the degree and direction of bias of Craigslist median rents with regards to HUD median rents by examining ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now calculate the ratio of median rents in filtered data set (per region and per # of bedrooms) to HUD median rents\n",
    "region_hud['hud_ratio_1'] = region_hud['clist_1'] / region_hud['HUD_median_1']\n",
    "region_hud['hud_ratio_2'] = region_hud['clist_2'] / region_hud['HUD_median_2']\n",
    "region_hud['hud_ratio_3'] = region_hud['clist_3'] / region_hud['HUD_median_3']\n",
    "region_hud['hud_ratio_4'] = region_hud['clist_4'] / region_hud['HUD_median_4']\n",
    "\n",
    "region_hud_means = region_hud[['hud_ratio_1','hud_ratio_2','hud_ratio_3','hud_ratio_4']].mean()\n",
    "region_hud_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average (arithmetic mean) in these regions, median rents in the filtered data set are 7.5% higher for 1 bedroom, 3.2% higher for 2 bedrooms, 7.2% lower for 3 bedrooms, and 1.2% higher for 4 bedrooms than the HUD 2014 median rent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add the mean values to the bottom then format all the ratios as +/- percentages\n",
    "region_hud_means.name='means'\n",
    "region_hud = region_hud.append(region_hud_means)\n",
    "cols = ['hud_ratio_1','hud_ratio_2','hud_ratio_3','hud_ratio_4']\n",
    "region_hud[cols] = region_hud[cols].applymap(lambda x: round(x, 2)).values\n",
    "region_hud[cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to csv and remove the means row\n",
    "region_hud.to_csv('processed-data/regions_hud_summary.csv')\n",
    "region_hud = region_hud.drop(labels='means', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, analyze listings counts and median rent per sq ft, by day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days_of_the_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many times does each day of the week appear in the data set of filtered listings\n",
    "listings_per_day = filtered_listings.groupby('day_of_week').size()\n",
    "listings_per_day.index = days_of_the_week\n",
    "listings_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many times does each day of the week appear in the data set of filtered listings\n",
    "listings_per_date = pd.DataFrame(filtered_listings['date'].value_counts())\n",
    "listings_per_date['day_of_week'] = listings_per_date.index.weekday\n",
    "day_counts = listings_per_date['day_of_week'].value_counts().sort_index()\n",
    "day_counts.index = days_of_the_week\n",
    "day_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many filtered listings per day of the week normalized by how many times that day appears in the data set\n",
    "avg_listings_per_day = listings_per_day / day_counts\n",
    "avg_listings_per_day.name = 'avg_count_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what is the median rent per day of the week\n",
    "median_rent_per_day = filtered_listings.groupby('day_of_week')['rent_sqft'].median().sort_index()\n",
    "median_rent_per_day.index = days_of_the_week\n",
    "median_rent_per_day.name = 'median_rent_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display a summary of the filtered data set, by day of the week\n",
    "day_summaries = pd.concat(objs=[avg_listings_per_day, median_rent_per_day], axis=1)\n",
    "day_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of listings posted and the median rent per square foot, per day of the week (filtered data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for comparison, create the same dataframe above, but for the original thorough set of listings\n",
    "all_listings_per_day = all_listings.groupby(all_listings['day_of_week']).size()\n",
    "all_listings_per_day.index = days_of_the_week\n",
    "all_listings_per_date = pd.DataFrame(all_listings['date'].value_counts())\n",
    "all_listings_per_date['day_of_week'] = all_listings_per_date.index.weekday\n",
    "all_day_counts = all_listings_per_date['day_of_week'].value_counts().sort_index()\n",
    "all_day_counts.index = days_of_the_week\n",
    "all_avg_listings_per_day = all_listings_per_day / all_day_counts\n",
    "all_avg_listings_per_day.name = 'avg_count_original'\n",
    "all_median_rent_per_day = all_listings.groupby(all_listings['day_of_week'])['rent_sqft'].median().sort_index()\n",
    "all_median_rent_per_day.index = days_of_the_week\n",
    "all_median_rent_per_day.name = 'median_rent_original'\n",
    "all_day_summaries = pd.concat(objs=[all_avg_listings_per_day, all_median_rent_per_day], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare the daily summaries from the original thorough data set, to those of the filtered set\n",
    "combined_summaries = pd.concat(objs=[day_summaries, all_day_summaries], axis=1)\n",
    "combined_summaries['count_ratio'] = combined_summaries['avg_count_filtered'] / combined_summaries['avg_count_original']\n",
    "combined_summaries['rent_ratio'] = combined_summaries['median_rent_filtered'] / combined_summaries['median_rent_original']\n",
    "combined_summaries = combined_summaries.reindex(columns=['avg_count_filtered','avg_count_original','count_ratio',\n",
    "                                                         'median_rent_filtered','median_rent_original','rent_ratio'])\n",
    "combined_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of listings posted and the median rent per square foot, by day of the week, for the original thorough data set and the filtered data set. Ratios show the ratio of the filtered set's value to the original set's value.\n",
    "\n",
    "Tuesdays have a noticeably higher ratio of unique, reasonable rental listings posted compared to Mondays. Explore that further, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for more comparison, create the same dataframe as earlier, but for the unique set of listings, pre-filter\n",
    "unique_listings_per_day = unique_listings.groupby(unique_listings['day_of_week']).size()\n",
    "unique_listings_per_day.index = days_of_the_week\n",
    "unique_listings_per_date = pd.DataFrame(unique_listings['date'].value_counts())\n",
    "unique_listings_per_date['day_of_week'] = unique_listings_per_date.index.weekday\n",
    "unique_day_counts = unique_listings_per_date['day_of_week'].value_counts().sort_index()\n",
    "unique_day_counts.index = days_of_the_week\n",
    "unique_avg_listings_per_day = unique_listings_per_day / unique_day_counts\n",
    "unique_avg_listings_per_day.name = 'avg_count_unique'\n",
    "unique_median_rent_per_day = unique_listings.groupby(unique_listings['day_of_week'])['rent_sqft'].median().sort_index()\n",
    "unique_median_rent_per_day.index = days_of_the_week\n",
    "unique_median_rent_per_day.name = 'median_rent_unique'\n",
    "unique_day_summaries = pd.concat(objs=[unique_avg_listings_per_day, unique_median_rent_per_day], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the ratios (original, unique, and filtered) side by side\n",
    "all_ratios = combined_summaries['avg_count_original'] / combined_summaries['avg_count_original'].sum()\n",
    "unique_ratios = unique_day_summaries['avg_count_unique'] / unique_day_summaries['avg_count_unique'].sum()\n",
    "filtered_ratios = combined_summaries['avg_count_filtered'] / combined_summaries['avg_count_filtered'].sum()\n",
    "\n",
    "avg_count_ratios = pd.concat(objs=[all_ratios, unique_ratios, filtered_ratios], axis=1)\n",
    "avg_count_ratios = avg_count_ratios.rename(columns={'avg_count_original':'original', \n",
    "                                                    'avg_count_unique':'unique', \n",
    "                                                    'avg_count_filtered':'filtered'})\n",
    "avg_count_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the ratios of rental listings (original, unique, and filtered) by day of week\n",
    "countdata = avg_count_ratios\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[8, 6], \n",
    "                    ylim=[0,.2],\n",
    "                    width=0.6, \n",
    "                    alpha=0.5,\n",
    "                    color=['r','b','g'],\n",
    "                    edgecolor='gray',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(map(lambda x: x, range(0, len(countdata))))\n",
    "ax.set_xticklabels(countdata.index, rotation=35, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Each day of the week\\'s ratio of total rental listings posted', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Ratio of listings posted per day', fontproperties=label_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'day_of_week_ratio_listings_posted.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is easy to see that Mondays account for a greater proportion of posted rental listings before we filter the data set for duplicates/re-posts and reasonable values. In contrast, Tuesdays account for a greater proportion of the listings after we filter the data set. It seems that Mondays suffer from more low quality postings, and Tuesdays have a greater ratio of high quality postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the avg number of filtered rental listings, by day of week\n",
    "countdata = avg_listings_per_day\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[8, 6], \n",
    "                    width=0.6, \n",
    "                    alpha=0.6,\n",
    "                    color='g',\n",
    "                    edgecolor='gray',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(map(lambda x: x, range(0, len(countdata))))\n",
    "ax.set_xticklabels(countdata.index, rotation=35, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Filtered rental listings posted, by day of the week', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Mean listings posted per day', fontproperties=label_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'day_of_week_listings_count_posted_filtered.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sundays see only half as many (filtered) listings posted as Mondays and Tuesdays do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now look at median rent/sqft by day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the median rent/sqft (original, unique, and filtered) side by side\n",
    "all_rent = combined_summaries['median_rent_original']\n",
    "unique_rent = unique_day_summaries['median_rent_unique']\n",
    "filtered_rent = combined_summaries['median_rent_filtered']\n",
    "\n",
    "median_rents = pd.concat(objs=[all_rent, unique_rent, filtered_rent], axis=1)\n",
    "median_rents = median_rents.rename(columns={'median_rent_original':'original', \n",
    "                                                    'median_rent_unique':'unique', \n",
    "                                                    'median_rent_filtered':'filtered'})\n",
    "median_rents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the median rent/sqft (original, unique, and filtered) by day of week\n",
    "countdata = median_rents\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[8, 6], \n",
    "                    ylim=[0, 1.4],\n",
    "                    width=0.6, \n",
    "                    alpha=0.5,\n",
    "                    color=['r','b','g'],\n",
    "                    edgecolor='gray',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(map(lambda x: x, range(0, len(countdata))))\n",
    "ax.set_xticklabels(countdata.index, rotation=35, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Median rent per square foot, by day of the week posted', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Median rent per square foot (USD)', fontproperties=label_font)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left')\n",
    "\n",
    "save_fig(plt.gcf(), 'day_of_week_median_rent_sqft.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the median rent per sq ft by day of the week for the filtered data set only\n",
    "countdata = median_rent_per_day\n",
    "ax = countdata.plot(kind='bar',                 \n",
    "                    figsize=[8, 6], \n",
    "                    width=0.6, \n",
    "                    alpha=0.7,\n",
    "                    color='g',\n",
    "                    edgecolor='gray',\n",
    "                    grid=False,\n",
    "                    ylim=[0, 1.4])\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(map(lambda x: x, range(0, len(countdata))))\n",
    "ax.set_xticklabels(countdata.index, rotation=35, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Median rent per square foot, by day of the week', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Median rent per square foot (USD)', fontproperties=label_font)\n",
    "\n",
    "save_fig(plt.gcf(), 'day_of_week_median_rent_sqft_filtered.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median rents are about 11.5% higher on Sundays (the most expensive day) than they are on Wednesdays (the least expensive day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Retain only the rows with lat-long data, then show descriptive stats for the different stages of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean data further by only retaining rows with lat-long data\n",
    "geolocated_filtered_listings = pd.DataFrame(filtered_listings)\n",
    "geolocated_filtered_listings = geolocated_filtered_listings[pd.notnull(geolocated_filtered_listings['latitude'])]\n",
    "geolocated_filtered_listings = geolocated_filtered_listings[pd.notnull(geolocated_filtered_listings['longitude'])]\n",
    "\n",
    "print len(geolocated_filtered_listings)\n",
    "print len(geolocated_filtered_listings) / float(len(filtered_listings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,456,338 geolocated listings in the filtered data set.\n",
    "\n",
    "To recap:\n",
    "\n",
    "- There were 10,958,372 rental listings in the original, full data set.\n",
    "- Of those total listings, 5,480,435 or 50.0% were unique.\n",
    "- Of those unique listings, 2,947,761 or 53.8% had rent, sqft, and reasonable values.\n",
    "- Of those filtered listings, 1,456,338 or 49.4% were geolocated.\n",
    "\n",
    "Interestingly, each filtering step retained almost exactly half of the remaining data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many regions are in the data set?\n",
    "print len(all_listings['region'].unique())\n",
    "print len(filtered_listings['region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(all_listings)\n",
    "all_listings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(unique_listings)\n",
    "unique_listings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(thorough_listings)\n",
    "thorough_listings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(filtered_listings)\n",
    "filtered_listings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(geolocated_filtered_listings)\n",
    "geolocated_filtered_listings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, save the geolocated filtered data to CSV for GIS mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only retain the relevant columns, then save the dataframe to csv\n",
    "cols = ['pid', 'date', 'region', 'neighborhood', 'rent', 'bedrooms', 'sqft', 'rent_sqft', \n",
    "        'rent_sqft_cat', 'longitude', 'latitude']\n",
    "data_output = geolocated_filtered_listings[cols]\n",
    "data_output.to_csv('processed-data/geolocated_filtered_listings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# also save a minimized csv with only category, lat, and long\n",
    "min_cols = ['rent_sqft_cat', 'longitude', 'latitude']\n",
    "data_output_min = geolocated_filtered_listings[min_cols]\n",
    "data_output_min.to_csv('processed-data/geolocated_filtered_listings_min.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
